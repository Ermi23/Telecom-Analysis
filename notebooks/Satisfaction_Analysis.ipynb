{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import the nessesary files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "c:\\Users\\ermias.tadesse\\10x\\Telecom-Analysis\\notebooks\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "print(os.getcwd())  # This prints the current working directory\n",
    "os.chdir(r'c:\\users\\ermias.tadesse\\10x\\Telecom-Analysis')  # Set the working directory to the project root\n",
    "import pandas as pd\n",
    "\n",
    "# Import the DBConnection and DataAnalysis classes\n",
    "from scripts.db_connection import DBConnection\n",
    "from scripts.Satisfaction_Analysis import TelecomSatisfactionAnalytics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create a connection "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully connected to the database!\n",
      "      Bearer Id            Start  Start ms              End  End ms  \\\n",
      "0  1.311448e+19   4/4/2019 12:01     770.0  4/25/2019 14:35   662.0   \n",
      "1  1.311448e+19   4/9/2019 13:04     235.0   4/25/2019 8:15   606.0   \n",
      "2  1.311448e+19   4/9/2019 17:42       1.0  4/25/2019 11:58   652.0   \n",
      "3  1.311448e+19   4/10/2019 0:31     486.0   4/25/2019 7:36   171.0   \n",
      "4  1.311448e+19  4/12/2019 20:10     565.0  4/25/2019 10:40   954.0   \n",
      "\n",
      "   Dur. (ms)          IMSI  MSISDN/Number          IMEI  \\\n",
      "0  1823652.0  2.082014e+14   3.366496e+10  3.552121e+13   \n",
      "1  1365104.0  2.082019e+14   3.368185e+10  3.579401e+13   \n",
      "2  1361762.0  2.082003e+14   3.376063e+10  3.528151e+13   \n",
      "3  1321509.0  2.082014e+14   3.375034e+10  3.535661e+13   \n",
      "4  1089009.0  2.082014e+14   3.369980e+10  3.540701e+13   \n",
      "\n",
      "      Last Location Name  ...  Youtube DL (Bytes)  Youtube UL (Bytes)  \\\n",
      "0  9.16456699548519E+015  ...          15854611.0           2501332.0   \n",
      "1                L77566A  ...          20247395.0          19111729.0   \n",
      "2                D42335A  ...          19725661.0          14699576.0   \n",
      "3                T21824A  ...          21388122.0          15146643.0   \n",
      "4                D88865A  ...          15259380.0          18962873.0   \n",
      "\n",
      "   Netflix DL (Bytes)  Netflix UL (Bytes)  Gaming DL (Bytes)  \\\n",
      "0           8198936.0           9656251.0        278082303.0   \n",
      "1          18338413.0          17227132.0        608750074.0   \n",
      "2          17587794.0           6163408.0        229584621.0   \n",
      "3          13994646.0           1097942.0        799538153.0   \n",
      "4          17124581.0            415218.0        527707248.0   \n",
      "\n",
      "   Gaming UL (Bytes)  Other DL (Bytes)  Other UL (Bytes)  Total UL (Bytes)  \\\n",
      "0         14344150.0       171744450.0         8814393.0        36749741.0   \n",
      "1          1170709.0       526904238.0        15055145.0        53800391.0   \n",
      "2           395630.0       410692588.0         4215763.0        27883638.0   \n",
      "3         10849722.0       749039933.0        12797283.0        43324218.0   \n",
      "4          3529801.0       550709500.0        13910322.0        38542814.0   \n",
      "\n",
      "   Total DL (Bytes)  \n",
      "0       308879636.0  \n",
      "1       653384965.0  \n",
      "2       279807335.0  \n",
      "3       846028530.0  \n",
      "4       569138589.0  \n",
      "\n",
      "[5 rows x 55 columns]\n"
     ]
    }
   ],
   "source": [
    "# Create a connection instance\n",
    "db = DBConnection(dbname='tele_co', user='postgres', password='Ermi@123')\n",
    "\n",
    "# Connect to the database\n",
    "db.connect()\n",
    "\n",
    "# Define a query to fetch data from the xdr_data table\n",
    "query = \"SELECT * FROM xdr_data;\"\n",
    "\n",
    "# Fetch data\n",
    "data = db.fetch_data(query)\n",
    "\n",
    "# Convert the data to a DataFrame\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Columns to clean\n",
    "columns_to_clean = ['TCP DL Retrans. Vol (Bytes)', 'TCP UL Retrans. Vol (Bytes)', \n",
    "                    'Avg RTT DL (ms)', 'Avg RTT UL (ms)', \n",
    "                    'Avg Bearer TP DL (kbps)', 'Avg Bearer TP UL (kbps)']\n",
    "    \n",
    "# Create a DataAnalysis instance\n",
    "analysis = TelecomSatisfactionAnalytics(data, columns_to_clean)\n",
    "\n",
    "# Check if data is returned\n",
    "if data is not None and not data.empty:\n",
    "    # Display the DataFrame\n",
    "    print(data.head())\n",
    "else:\n",
    "    print(\"No data available or data is empty.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      Bearer Id            Start  Start ms              End  End ms  \\\n",
      "0  1.311448e+19   4/4/2019 12:01     770.0  4/25/2019 14:35   662.0   \n",
      "1  1.311448e+19   4/9/2019 13:04     235.0   4/25/2019 8:15   606.0   \n",
      "2  1.311448e+19   4/9/2019 17:42       1.0  4/25/2019 11:58   652.0   \n",
      "3  1.311448e+19   4/10/2019 0:31     486.0   4/25/2019 7:36   171.0   \n",
      "4  1.311448e+19  4/12/2019 20:10     565.0  4/25/2019 10:40   954.0   \n",
      "\n",
      "   Dur. (ms)          IMSI  MSISDN/Number          IMEI  \\\n",
      "0  1823652.0  2.082014e+14   3.366496e+10  3.552121e+13   \n",
      "1  1365104.0  2.082019e+14   3.368185e+10  3.579401e+13   \n",
      "2  1361762.0  2.082003e+14   3.376063e+10  3.528151e+13   \n",
      "3  1321509.0  2.082014e+14   3.375034e+10  3.535661e+13   \n",
      "4  1089009.0  2.082014e+14   3.369980e+10  3.540701e+13   \n",
      "\n",
      "      Last Location Name  ...  Youtube DL (Bytes)  Youtube UL (Bytes)  \\\n",
      "0  9.16456699548519E+015  ...          15854611.0           2501332.0   \n",
      "1                L77566A  ...          20247395.0          19111729.0   \n",
      "2                D42335A  ...          19725661.0          14699576.0   \n",
      "3                T21824A  ...          21388122.0          15146643.0   \n",
      "4                D88865A  ...          15259380.0          18962873.0   \n",
      "\n",
      "   Netflix DL (Bytes)  Netflix UL (Bytes)  Gaming DL (Bytes)  \\\n",
      "0           8198936.0           9656251.0        278082303.0   \n",
      "1          18338413.0          17227132.0        608750074.0   \n",
      "2          17587794.0           6163408.0        229584621.0   \n",
      "3          13994646.0           1097942.0        799538153.0   \n",
      "4          17124581.0            415218.0        527707248.0   \n",
      "\n",
      "   Gaming UL (Bytes)  Other DL (Bytes)  Other UL (Bytes)  Total UL (Bytes)  \\\n",
      "0         14344150.0       171744450.0         8814393.0        36749741.0   \n",
      "1          1170709.0       526904238.0        15055145.0        53800391.0   \n",
      "2           395630.0       410692588.0         4215763.0        27883638.0   \n",
      "3         10849722.0       749039933.0        12797283.0        43324218.0   \n",
      "4          3529801.0       550709500.0        13910322.0        38542814.0   \n",
      "\n",
      "   Total DL (Bytes)  \n",
      "0       308879636.0  \n",
      "1       653384965.0  \n",
      "2       279807335.0  \n",
      "3       846028530.0  \n",
      "4       569138589.0  \n",
      "\n",
      "[5 rows x 55 columns]\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Input X contains NaN.\nKMeans does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[3], line 9\u001b[0m\n\u001b[0;32m      6\u001b[0m     \u001b[38;5;28mprint\u001b[39m(df\u001b[38;5;241m.\u001b[39mhead())\n\u001b[0;32m      8\u001b[0m \u001b[38;5;66;03m# Task execution\u001b[39;00m\n\u001b[1;32m----> 9\u001b[0m \u001b[43manalysis\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mperform_clustering\u001b[49m\u001b[43m(\u001b[49m\u001b[43mn_clusters\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# Perform clustering\u001b[39;00m\n\u001b[0;32m     11\u001b[0m \u001b[38;5;66;03m# Now you can calculate scores\u001b[39;00m\n\u001b[0;32m     12\u001b[0m analysis\u001b[38;5;241m.\u001b[39mcalculate_scores(engagement_cluster\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m, experience_cluster\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n",
      "File \u001b[1;32mc:\\users\\ermias.tadesse\\10x\\Telecom-Analysis\\scripts\\Satisfaction_Analysis.py:32\u001b[0m, in \u001b[0;36mTelecomSatisfactionAnalytics.perform_clustering\u001b[1;34m(self, n_clusters)\u001b[0m\n\u001b[0;32m     30\u001b[0m \u001b[38;5;66;03m# Perform k-means clustering\u001b[39;00m\n\u001b[0;32m     31\u001b[0m kmeans \u001b[38;5;241m=\u001b[39m KMeans(n_clusters\u001b[38;5;241m=\u001b[39mn_clusters, random_state\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m42\u001b[39m)\n\u001b[1;32m---> 32\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdf[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mCluster\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[43mkmeans\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit_predict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmetrics_scaled\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\ermias.tadesse\\10x\\Telecom-Analysis\\venv\\Lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1070\u001b[0m, in \u001b[0;36m_BaseKMeans.fit_predict\u001b[1;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[0;32m   1047\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfit_predict\u001b[39m(\u001b[38;5;28mself\u001b[39m, X, y\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, sample_weight\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[0;32m   1048\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Compute cluster centers and predict cluster index for each sample.\u001b[39;00m\n\u001b[0;32m   1049\u001b[0m \n\u001b[0;32m   1050\u001b[0m \u001b[38;5;124;03m    Convenience method; equivalent to calling fit(X) followed by\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1068\u001b[0m \u001b[38;5;124;03m        Index of the cluster each sample belongs to.\u001b[39;00m\n\u001b[0;32m   1069\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m-> 1070\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msample_weight\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mlabels_\n",
      "File \u001b[1;32mc:\\Users\\ermias.tadesse\\10x\\Telecom-Analysis\\venv\\Lib\\site-packages\\sklearn\\base.py:1473\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[1;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1466\u001b[0m     estimator\u001b[38;5;241m.\u001b[39m_validate_params()\n\u001b[0;32m   1468\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[0;32m   1469\u001b[0m     skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[0;32m   1470\u001b[0m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[0;32m   1471\u001b[0m     )\n\u001b[0;32m   1472\u001b[0m ):\n\u001b[1;32m-> 1473\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfit_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\ermias.tadesse\\10x\\Telecom-Analysis\\venv\\Lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1464\u001b[0m, in \u001b[0;36mKMeans.fit\u001b[1;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[0;32m   1436\u001b[0m \u001b[38;5;129m@_fit_context\u001b[39m(prefer_skip_nested_validation\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m   1437\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfit\u001b[39m(\u001b[38;5;28mself\u001b[39m, X, y\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, sample_weight\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[0;32m   1438\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Compute k-means clustering.\u001b[39;00m\n\u001b[0;32m   1439\u001b[0m \n\u001b[0;32m   1440\u001b[0m \u001b[38;5;124;03m    Parameters\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1462\u001b[0m \u001b[38;5;124;03m        Fitted estimator.\u001b[39;00m\n\u001b[0;32m   1463\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m-> 1464\u001b[0m     X \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_validate_data\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1465\u001b[0m \u001b[43m        \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1466\u001b[0m \u001b[43m        \u001b[49m\u001b[43maccept_sparse\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcsr\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1467\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfloat64\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfloat32\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1468\u001b[0m \u001b[43m        \u001b[49m\u001b[43morder\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mC\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1469\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcopy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcopy_x\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1470\u001b[0m \u001b[43m        \u001b[49m\u001b[43maccept_large_sparse\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m   1471\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1473\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_params_vs_input(X)\n\u001b[0;32m   1475\u001b[0m     random_state \u001b[38;5;241m=\u001b[39m check_random_state(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrandom_state)\n",
      "File \u001b[1;32mc:\\Users\\ermias.tadesse\\10x\\Telecom-Analysis\\venv\\Lib\\site-packages\\sklearn\\base.py:633\u001b[0m, in \u001b[0;36mBaseEstimator._validate_data\u001b[1;34m(self, X, y, reset, validate_separately, cast_to_ndarray, **check_params)\u001b[0m\n\u001b[0;32m    631\u001b[0m         out \u001b[38;5;241m=\u001b[39m X, y\n\u001b[0;32m    632\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m no_val_X \u001b[38;5;129;01mand\u001b[39;00m no_val_y:\n\u001b[1;32m--> 633\u001b[0m     out \u001b[38;5;241m=\u001b[39m \u001b[43mcheck_array\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minput_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mX\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mcheck_params\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    634\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m no_val_X \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m no_val_y:\n\u001b[0;32m    635\u001b[0m     out \u001b[38;5;241m=\u001b[39m _check_y(y, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mcheck_params)\n",
      "File \u001b[1;32mc:\\Users\\ermias.tadesse\\10x\\Telecom-Analysis\\venv\\Lib\\site-packages\\sklearn\\utils\\validation.py:1064\u001b[0m, in \u001b[0;36mcheck_array\u001b[1;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_writeable, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator, input_name)\u001b[0m\n\u001b[0;32m   1058\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m   1059\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFound array with dim \u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[38;5;124m. \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m expected <= 2.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1060\u001b[0m         \u001b[38;5;241m%\u001b[39m (array\u001b[38;5;241m.\u001b[39mndim, estimator_name)\n\u001b[0;32m   1061\u001b[0m     )\n\u001b[0;32m   1063\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m force_all_finite:\n\u001b[1;32m-> 1064\u001b[0m     \u001b[43m_assert_all_finite\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1065\u001b[0m \u001b[43m        \u001b[49m\u001b[43marray\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1066\u001b[0m \u001b[43m        \u001b[49m\u001b[43minput_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minput_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1067\u001b[0m \u001b[43m        \u001b[49m\u001b[43mestimator_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mestimator_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1068\u001b[0m \u001b[43m        \u001b[49m\u001b[43mallow_nan\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mforce_all_finite\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m==\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mallow-nan\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1069\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1071\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m copy:\n\u001b[0;32m   1072\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m _is_numpy_namespace(xp):\n\u001b[0;32m   1073\u001b[0m         \u001b[38;5;66;03m# only make a copy if `array` and `array_orig` may share memory`\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\ermias.tadesse\\10x\\Telecom-Analysis\\venv\\Lib\\site-packages\\sklearn\\utils\\validation.py:123\u001b[0m, in \u001b[0;36m_assert_all_finite\u001b[1;34m(X, allow_nan, msg_dtype, estimator_name, input_name)\u001b[0m\n\u001b[0;32m    120\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m first_pass_isfinite:\n\u001b[0;32m    121\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[1;32m--> 123\u001b[0m \u001b[43m_assert_all_finite_element_wise\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    124\u001b[0m \u001b[43m    \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    125\u001b[0m \u001b[43m    \u001b[49m\u001b[43mxp\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mxp\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    126\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_nan\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mallow_nan\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    127\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmsg_dtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmsg_dtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    128\u001b[0m \u001b[43m    \u001b[49m\u001b[43mestimator_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mestimator_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    129\u001b[0m \u001b[43m    \u001b[49m\u001b[43minput_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minput_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    130\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\ermias.tadesse\\10x\\Telecom-Analysis\\venv\\Lib\\site-packages\\sklearn\\utils\\validation.py:172\u001b[0m, in \u001b[0;36m_assert_all_finite_element_wise\u001b[1;34m(X, xp, allow_nan, msg_dtype, estimator_name, input_name)\u001b[0m\n\u001b[0;32m    155\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m estimator_name \u001b[38;5;129;01mand\u001b[39;00m input_name \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mX\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m has_nan_error:\n\u001b[0;32m    156\u001b[0m     \u001b[38;5;66;03m# Improve the error message on how to handle missing values in\u001b[39;00m\n\u001b[0;32m    157\u001b[0m     \u001b[38;5;66;03m# scikit-learn.\u001b[39;00m\n\u001b[0;32m    158\u001b[0m     msg_err \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m    159\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mestimator_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m does not accept missing values\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    160\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m encoded as NaN natively. For supervised learning, you might want\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    170\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m#estimators-that-handle-nan-values\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    171\u001b[0m     )\n\u001b[1;32m--> 172\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(msg_err)\n",
      "\u001b[1;31mValueError\u001b[0m: Input X contains NaN.\nKMeans does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values"
     ]
    }
   ],
   "source": [
    "analysis.clean_data()\n",
    "analysis.fill_missing_with_mean()\n",
    "\n",
    "# Check if data is returned\n",
    "if not df.empty:\n",
    "    print(df.head())\n",
    "\n",
    "# Task execution\n",
    "analysis.perform_clustering(n_clusters=2)  # Perform clustering\n",
    "\n",
    "# Now you can calculate scores\n",
    "analysis.calculate_scores(engagement_cluster=0, experience_cluster=1)\n",
    "analysis.calculate_satisfaction_score()\n",
    "top_satisfied = analysis.report_top_satisfied()\n",
    "print(top_satisfied)\n",
    "\n",
    "analysis.build_regression_model()\n",
    "analysis.run_kmeans_on_scores()\n",
    "aggregate_scores = analysis.aggregate_scores()\n",
    "print(aggregate_scores)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
